---
name: example-ollama

services:
  ollama:
    build:
      dockerfile: ./ollama/sycl/Dockerfile
      context: ../..
    image: ghcr.io/futursolo/portable-ai/ollama:sycl
    devices:
      - /dev/dri:/dev/dri
    environment:
      TZ: Etc/UTC
    group_add:
      - video
    ports:
      - 5001:5001
    restart: unless-stopped
    command: >
      --contextsize 8192
      --model /home/docker-user/models/Llama-3.3-70B-Instruct-Q4_K_M.gguf
      --usevulkan --port 5001 --quiet
      --password mypassword
    security_opt:
      - seccomp:unconfined
    volumes:
      - read_only: true
        source: ../../test-models
        target: /home/docker-user/models
        type: bind
